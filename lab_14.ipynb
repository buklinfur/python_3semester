{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "kmMliM9xkFtw"
      ],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMh2OnHQ7tW02Gh3ihcjKWd"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Семинарские задания"
      ],
      "metadata": {
        "id": "kmMliM9xkFtw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Написать функцию, переводящую изображение в матрицу столбцов - im2col(). На вход функция принимает изображение и размер свёртки, возвращает столбцы."
      ],
      "metadata": {
        "id": "c0pvMCaQkM_A"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "AtkRpf8fQby5"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def im2col(image, kernel_size):\n",
        "    kH, kW = kernel_size\n",
        "\n",
        "    if len(image.shape) == 3:\n",
        "        H, W, C = image.shape\n",
        "        image_padded = image\n",
        "        is_color = True\n",
        "    elif len(image.shape) == 2:\n",
        "        H, W = image.shape\n",
        "        image_padded = image\n",
        "        C = 1\n",
        "        is_color = False\n",
        "    else:\n",
        "        raise ValueError(\"Image must be either 2D (grayscale) or 3D (color).\")\n",
        "\n",
        "    out_height = H - kH + 1\n",
        "    out_width = W - kW + 1\n",
        "\n",
        "    cols = []\n",
        "\n",
        "    for y in range(out_height):\n",
        "        for x in range(out_width):\n",
        "            if is_color:\n",
        "                patch = image_padded[y:y+kH, x:x+kW, :]\n",
        "                patch_flattened = patch.reshape(-1)\n",
        "            else:\n",
        "                patch = image_padded[y:y+kH, x:x+kW]\n",
        "                patch_flattened = patch.flatten()\n",
        "            cols.append(patch_flattened)\n",
        "\n",
        "    cols = np.array(cols).T\n",
        "    return cols"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Написать функцию свёртки, которая работает без циклов. Вместо циклов, она использует im2col(), для перевода изображения в набор столбцов."
      ],
      "metadata": {
        "id": "NZgILR8RkUbe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def convolve_with_im2col(image, kernel, stride=1, padding=0):\n",
        "    kH, kW = kernel.shape\n",
        "\n",
        "    # Flatten the kernel\n",
        "    kernel_flattened = kernel.flatten()\n",
        "\n",
        "    cols = im2col(image, (kH, kW))\n",
        "\n",
        "    result = np.dot(kernel_flattened, cols)\n",
        "\n",
        "    # Reshape the result to output dimensions\n",
        "    out_height = (image.shape[0] + 2 * padding - kH) // stride + 1\n",
        "    out_width = (image.shape[1] + 2 * padding - kW) // stride + 1\n",
        "\n",
        "    return result.reshape(out_height, out_width)"
      ],
      "metadata": {
        "id": "kYHqUpSgkX-y"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Сравнить результаты с torch.nn.Conv2d"
      ],
      "metadata": {
        "id": "yPoNhqfgkYeK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn.functional import conv2d\n",
        "\n",
        "image_np = np.random.rand(8, 8).astype(np.float32)  # Random 8x8 image\n",
        "kernel_np = np.array([[1, 0, -1], [1, 0, -1], [1, 0, -1]], dtype=np.float32)  # 3x3 kernel\n",
        "\n",
        "custom_output = convolve_with_im2col(image_np, kernel_np, stride=1, padding=0)\n",
        "\n",
        "image_torch = torch.tensor(image_np).unsqueeze(0).unsqueeze(0)  # Add batch and channel dimensions\n",
        "kernel_torch = torch.tensor(kernel_np).unsqueeze(0).unsqueeze(0)  # Add out_channels and in_channels dimensions\n",
        "\n",
        "conv2d_layer = nn.Conv2d(in_channels=1, out_channels=1, kernel_size=3, stride=1, padding=0, bias=False)\n",
        "conv2d_layer.weight.data = kernel_torch  # Set custom kernel weights\n",
        "\n",
        "torch_output = conv2d_layer(image_torch).squeeze().detach().numpy()\n",
        "\n",
        "print(\"Custom im2col-based Convolution Output:\\n\", custom_output)\n",
        "print(\"Torch Conv2d Output:\\n\", torch_output)\n",
        "\n",
        "if np.allclose(custom_output, torch_output, atol=1e-5):\n",
        "    print(\"The outputs match!\")\n",
        "else:\n",
        "    print(\"The outputs do not match.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KV3bmi1Dkd-j",
        "outputId": "4d73319f-2b58-442d-a684-a4666aedade5"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Custom im2col-based Convolution Output:\n",
            " [[-0.26550096 -0.03610522 -0.1310561   0.1083349   0.49020314  0.864507  ]\n",
            " [-0.36179203  0.15752113  0.5345055   0.70685256  0.17434216 -0.37750995]\n",
            " [-0.41467357 -0.43938458  0.60901916  0.52416074  0.31242156  0.38971603]\n",
            " [ 0.24081478 -0.62062234 -0.80593014  0.6867244   0.42825848  0.30668533]\n",
            " [-0.0899545  -1.0970418  -0.14868686  0.6273838   0.06175262  0.8289969 ]\n",
            " [ 0.2581129  -1.3067826   0.44732565  1.4011619  -0.39400145 -0.639328  ]]\n",
            "Torch Conv2d Output:\n",
            " [[-0.26550096 -0.03610516 -0.13105613  0.1083349   0.4902032   0.864507  ]\n",
            " [-0.36179197  0.15752119  0.5345055   0.70685256  0.17434216 -0.37750995]\n",
            " [-0.41467357 -0.43938458  0.6090193   0.5241606   0.3124215   0.38971606]\n",
            " [ 0.24081483 -0.62062234 -0.80593014  0.6867244   0.42825848  0.30668533]\n",
            " [-0.08995456 -1.0970418  -0.14868686  0.6273838   0.06175262  0.8289969 ]\n",
            " [ 0.2581129  -1.3067826   0.44732565  1.4011619  -0.39400145 -0.639328  ]]\n",
            "The outputs match!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Лабораторная работа"
      ],
      "metadata": {
        "id": "AN5c0aCwkfC6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Задача классификации изображений (https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html?highlight=mnist). Повторить тренировку модели (train) и запустить классификацию изображений (inference).\n",
        "2. Получить максимальную точность классификации (минимальный loss) путём изменения модели, например, добавлением скрытых слоёв.\n",
        "3. По возможности обучить на GPU."
      ],
      "metadata": {
        "id": "PopAAHflki1o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  # Normalize images\n",
        "])\n",
        "\n",
        "batch_size = 4\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cQi8bSvtky8v",
        "outputId": "95dab788-84f3-4589-b109-7fcb0630e7d4"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda:0\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class CNNModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNNModel, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 6, 5)  # 3 input channels, 6 output, 5x5 kernel\n",
        "        self.pool = nn.MaxPool2d(2, 2)   # 2x2 max pooling\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 16 * 5 * 5)  # Flatten\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "iSSEv_lGxD2t"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ImprovedModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ImprovedModel, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 32, 3, padding=1)\n",
        "        self.conv2 = nn.Conv2d(32, 64, 3, padding=1)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.fc1 = nn.Linear(64 * 8 * 8, 256)\n",
        "        self.fc2 = nn.Linear(256, 128)\n",
        "        self.fc3 = nn.Linear(128, 10)\n",
        "        self.dropout = nn.Dropout(0.5)  # Dropout regularization\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 64 * 8 * 8)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "xeEgXSQ0xcOm"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, trainloader, criterion, optimizer, device, epochs=10):\n",
        "    model.to(device)\n",
        "    model.train()\n",
        "\n",
        "    print(\"Starting Training...\")\n",
        "    for epoch in range(epochs):\n",
        "        running_loss = 0.0\n",
        "        for i, data in enumerate(trainloader, 0):\n",
        "            # Get inputs and labels, and move to the correct device\n",
        "            inputs, labels = data[0].to(device), data[1].to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            if (i + 1) % 2000 == 0:\n",
        "                print(f\"[Epoch {epoch + 1}, Batch {i + 1}] loss: {running_loss / 2000:.3f}\")\n",
        "                running_loss = 0.0\n",
        "\n",
        "    print(\"Finished Training\")"
      ],
      "metadata": {
        "id": "y5Ly0qn8xrop"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = CNNModel()\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "train(model, trainloader, criterion, optimizer, device, epochs=5)\n",
        "\n",
        "torch.save(model.state_dict(), \"cifar_net.pth\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "krk-IACs1Rf1",
        "outputId": "c01b760c-74e3-4818-f343-321c5f6b5ff1"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting Training...\n",
            "[Epoch 1, Batch 2000] loss: 1.881\n",
            "[Epoch 1, Batch 4000] loss: 1.621\n",
            "[Epoch 1, Batch 6000] loss: 1.536\n",
            "[Epoch 1, Batch 8000] loss: 1.480\n",
            "[Epoch 1, Batch 10000] loss: 1.426\n",
            "[Epoch 1, Batch 12000] loss: 1.403\n",
            "[Epoch 2, Batch 2000] loss: 1.307\n",
            "[Epoch 2, Batch 4000] loss: 1.317\n",
            "[Epoch 2, Batch 6000] loss: 1.293\n",
            "[Epoch 2, Batch 8000] loss: 1.289\n",
            "[Epoch 2, Batch 10000] loss: 1.282\n",
            "[Epoch 2, Batch 12000] loss: 1.231\n",
            "[Epoch 3, Batch 2000] loss: 1.176\n",
            "[Epoch 3, Batch 4000] loss: 1.210\n",
            "[Epoch 3, Batch 6000] loss: 1.191\n",
            "[Epoch 3, Batch 8000] loss: 1.196\n",
            "[Epoch 3, Batch 10000] loss: 1.174\n",
            "[Epoch 3, Batch 12000] loss: 1.177\n",
            "[Epoch 4, Batch 2000] loss: 1.111\n",
            "[Epoch 4, Batch 4000] loss: 1.126\n",
            "[Epoch 4, Batch 6000] loss: 1.118\n",
            "[Epoch 4, Batch 8000] loss: 1.131\n",
            "[Epoch 4, Batch 10000] loss: 1.136\n",
            "[Epoch 4, Batch 12000] loss: 1.093\n",
            "[Epoch 5, Batch 2000] loss: 1.066\n",
            "[Epoch 5, Batch 4000] loss: 1.068\n",
            "[Epoch 5, Batch 6000] loss: 1.078\n",
            "[Epoch 5, Batch 8000] loss: 1.071\n",
            "[Epoch 5, Batch 10000] loss: 1.085\n",
            "[Epoch 5, Batch 12000] loss: 1.078\n",
            "Finished Training\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = CNNModel().to(device)\n",
        "model.load_state_dict(torch.load(\"cifar_net.pth\", weights_only=False))\n",
        "\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        images, labels = data[0].to(device), data[1].to(device)\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f\"Accuracy on 10,000 test images: {100 * correct / total:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OMifOPMz1-nI",
        "outputId": "50ef2eaa-e6c0-4ad4-f8c9-685c6229ba4c"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy on 10,000 test images: 59.46%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = ImprovedModel()\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "train(model, trainloader, criterion, optimizer, device, epochs=5)\n",
        "\n",
        "torch.save(model.state_dict(), \"improved_cifar_net.pth\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ba5_Bnnuytsk",
        "outputId": "802e9747-ea60-411a-96f8-61a0a67df332"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting Training...\n",
            "[Epoch 1, Batch 2000] loss: 1.866\n",
            "[Epoch 1, Batch 4000] loss: 1.574\n",
            "[Epoch 1, Batch 6000] loss: 1.454\n",
            "[Epoch 1, Batch 8000] loss: 1.400\n",
            "[Epoch 1, Batch 10000] loss: 1.341\n",
            "[Epoch 1, Batch 12000] loss: 1.318\n",
            "[Epoch 2, Batch 2000] loss: 1.226\n",
            "[Epoch 2, Batch 4000] loss: 1.200\n",
            "[Epoch 2, Batch 6000] loss: 1.200\n",
            "[Epoch 2, Batch 8000] loss: 1.173\n",
            "[Epoch 2, Batch 10000] loss: 1.184\n",
            "[Epoch 2, Batch 12000] loss: 1.154\n",
            "[Epoch 3, Batch 2000] loss: 1.069\n",
            "[Epoch 3, Batch 4000] loss: 1.071\n",
            "[Epoch 3, Batch 6000] loss: 1.072\n",
            "[Epoch 3, Batch 8000] loss: 1.094\n",
            "[Epoch 3, Batch 10000] loss: 1.090\n",
            "[Epoch 3, Batch 12000] loss: 1.070\n",
            "[Epoch 4, Batch 2000] loss: 0.991\n",
            "[Epoch 4, Batch 4000] loss: 0.994\n",
            "[Epoch 4, Batch 6000] loss: 0.982\n",
            "[Epoch 4, Batch 8000] loss: 1.018\n",
            "[Epoch 4, Batch 10000] loss: 1.030\n",
            "[Epoch 4, Batch 12000] loss: 1.033\n",
            "[Epoch 5, Batch 2000] loss: 0.922\n",
            "[Epoch 5, Batch 4000] loss: 0.960\n",
            "[Epoch 5, Batch 6000] loss: 0.962\n",
            "[Epoch 5, Batch 8000] loss: 0.970\n",
            "[Epoch 5, Batch 10000] loss: 0.962\n",
            "[Epoch 5, Batch 12000] loss: 0.980\n",
            "Finished Training\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = ImprovedModel().to(device)\n",
        "\n",
        "model.load_state_dict(torch.load(\"improved_cifar_net.pth\", weights_only=False))\n",
        "\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        images, labels = data[0].to(device), data[1].to(device)\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f\"Accuracy on 10,000 test images: {100 * correct / total:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aCunUDoi0j8d",
        "outputId": "d0463939-bba0-411e-d988-c56b9c0130a1"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy on 10,000 test images: 63.87%\n"
          ]
        }
      ]
    }
  ]
}